{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist_estimator.ipynb",
      "version": "0.3.2",
      "provenance": []
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "EkhlaP1lTCTC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Using the TensorFlow Estimator APIs\n",
        "\n",
        "In this lab, we'll explore using TensorFlow's high-level [`tf.estimator`](https://www.tensorflow.org/programmers_guide/estimators) APIs, in order to easily build, train, evaluate, and use NN models.\n",
        "\n",
        "We'll do this via both the 'MNIST' dataset, and [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist/blob/master/doc/img/fashion-mnist-sprite.png), which is a direct drop-in replacement for the original MNIST dataset.\n",
        "(You can read more about it, and why it was created, [here](https://github.com/zalandoresearch/fashion-mnist). It is a more challenging dataset than 'regular' MNIST, which has become too easy these days.)\n",
        "\n",
        "The lab starts with a [`LinearClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/LinearClassifier), then uses a [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) with multiple hidden layers.\n",
        "\n",
        "As part of the lab, we'll explore what [TensorBoard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) can do.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "ktYeCFKkTCTE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**If you're running this notebook on colab**, download the dataset.py file from the repo:"
      ]
    },
    {
      "metadata": {
        "id": "mpq28ztcTCTG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "392f9d59-19f6-49db-af4b-a395c9a653a5"
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "wget https://raw.githubusercontent.com/amygdala/tensorflow-workshop/master/workshop_sections/high_level_APIs/dataset.py\n",
        "ls -l dataset.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root root 4347 Aug 17 19:11 dataset.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2018-08-17 19:11:35--  https://raw.githubusercontent.com/amygdala/tensorflow-workshop/master/workshop_sections/high_level_APIs/dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4347 (4.2K) [text/plain]\n",
            "Saving to: ‘dataset.py’\n",
            "\n",
            "     0K ....                                                  100% 71.3M=0s\n",
            "\n",
            "2018-08-17 19:11:35 (71.3 MB/s) - ‘dataset.py’ saved [4347/4347]\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "-VrSFCaNTCTJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Do some imports and check your version of TensorFlow.  It must be >=1.4, and ideally >=1.7."
      ]
    },
    {
      "metadata": {
        "id": "pNM3_aaDTCTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28d023cf-19a9-47d6-df46-42c9b1f7b332"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "\n",
        "import tensorflow as tf\n",
        "import dataset\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "# define a utility function for generating a new directory in which to save \n",
        "# model information, so multiple training runs don't stomp on each other.\n",
        "def get_new_path(name=\"\"):\n",
        "    base = os.path.abspath(\"/tmp/tfmodels/mnist_estimators\")\n",
        "    logpath = os.path.join(base, name + \"_\" + str(int(time.time())))\n",
        "    print(\"Logging to {}\".format(logpath))\n",
        "    return logpath"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HOubNweqTCTT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Getting started: A Linear Classifier\n",
        "\n",
        "First, let's build a LinearClassifier. \n",
        "\n",
        "We'll first build the models' input functions.\n",
        "\n",
        "We'll use [Datasets](https://www.tensorflow.org/get_started/datasets_quickstart) to manage the input to our model. The [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) module contains a collection of classes that allows you to easily load data, manipulate it, and pipe it into your model. \n",
        "[Datasets support highly scalable and performant input pipelines](https://www.tensorflow.org/performance/datasets_performance), and it is best practice to use them where possible.\n"
      ]
    },
    {
      "metadata": {
        "id": "5o2uOgz_TCTU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/tmp/MNIST_data\"\n",
        "NUM_STEPS = 5000\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "def train_input_fn(data_dir, batch_size=100):\n",
        "  \"\"\"Prepare data for training.\"\"\"\n",
        "\n",
        "  # When choosing shuffle buffer sizes, larger sizes result in better\n",
        "  # randomness, while smaller sizes use less memory. MNIST is a small\n",
        "  # enough dataset that we can easily shuffle the full epoch.\n",
        "  ds = dataset.train(data_dir)\n",
        "  ds = ds.cache().shuffle(buffer_size=50000).batch(batch_size=batch_size)\n",
        "\n",
        "  # Iterate through the dataset a set number of times\n",
        "  # during each training session.\n",
        "  ds = ds.repeat(40)\n",
        "  features = ds.make_one_shot_iterator().get_next()\n",
        "  return {'pixels': features[0]}, features[1]\n",
        "\n",
        "\n",
        "def eval_input_fn(data_dir, batch_size=100):\n",
        "  features = dataset.test(data_dir).batch(\n",
        "      batch_size=batch_size).make_one_shot_iterator().get_next()\n",
        "  return {'pixels': features[0]}, features[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c6VkXPyHTCTZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now, we'll define and train the LinearClassifier model.\n",
        "Note that we didn't need to explicitly define a model graph or a training loop ourselves.\n"
      ]
    },
    {
      "metadata": {
        "id": "IK5U2AT2TCTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1975
        },
        "outputId": "ef80c316-4e33-4e1c-a04e-1a9a5e9d95d3"
      },
      "cell_type": "code",
      "source": [
        "feature_columns = [tf.feature_column.numeric_column(\n",
        "    \"pixels\", shape=784)]\n",
        "\n",
        "linear_classifier = tf.estimator.LinearClassifier(\n",
        "        feature_columns=feature_columns, \n",
        "        n_classes=10,\n",
        "        model_dir=get_new_path(\"linear\")\n",
        "    )\n",
        "\n",
        "train_input = lambda: train_input_fn(\n",
        "    DATA_DIR,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "linear_classifier.train(input_fn=train_input, steps=NUM_STEPS)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/tfmodels/mnist_estimators/linear_1534533340\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1a4a4a0cd0>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tfmodels/mnist_estimators/linear_1534533340', '_train_distribute': None, '_save_summary_steps': 100}\n",
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz to /tmp/tmp4DaxpG.gz\n",
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz to /tmp/tmpVE4Tji.gz\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tfmodels/mnist_estimators/linear_1534533340/model.ckpt.\n",
            "INFO:tensorflow:loss = 230.25854, step = 1\n",
            "INFO:tensorflow:global_step/sec: 55.1012\n",
            "INFO:tensorflow:loss = 54.08279, step = 101 (1.816 sec)\n",
            "INFO:tensorflow:global_step/sec: 563.158\n",
            "INFO:tensorflow:loss = 24.174583, step = 201 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 558.703\n",
            "INFO:tensorflow:loss = 31.948078, step = 301 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 558.107\n",
            "INFO:tensorflow:loss = 25.108473, step = 401 (0.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.582\n",
            "INFO:tensorflow:loss = 13.469546, step = 501 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 518.911\n",
            "INFO:tensorflow:loss = 30.17773, step = 601 (0.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.906\n",
            "INFO:tensorflow:loss = 45.258705, step = 701 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 570.754\n",
            "INFO:tensorflow:loss = 32.33888, step = 801 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 554.33\n",
            "INFO:tensorflow:loss = 23.408516, step = 901 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 543.157\n",
            "INFO:tensorflow:loss = 29.65086, step = 1001 (0.184 sec)\n",
            "INFO:tensorflow:global_step/sec: 571.219\n",
            "INFO:tensorflow:loss = 19.108196, step = 1101 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 497.292\n",
            "INFO:tensorflow:loss = 20.035036, step = 1201 (0.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.232\n",
            "INFO:tensorflow:loss = 41.729023, step = 1301 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 575.311\n",
            "INFO:tensorflow:loss = 19.012947, step = 1401 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.145\n",
            "INFO:tensorflow:loss = 21.181557, step = 1501 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 558.981\n",
            "INFO:tensorflow:loss = 35.91779, step = 1601 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.93\n",
            "INFO:tensorflow:loss = 38.749332, step = 1701 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.638\n",
            "INFO:tensorflow:loss = 16.817108, step = 1801 (0.189 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.251\n",
            "INFO:tensorflow:loss = 30.77373, step = 1901 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.621\n",
            "INFO:tensorflow:loss = 25.068964, step = 2001 (0.173 sec)\n",
            "INFO:tensorflow:global_step/sec: 553.382\n",
            "INFO:tensorflow:loss = 20.034653, step = 2101 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 576.917\n",
            "INFO:tensorflow:loss = 23.85172, step = 2201 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.444\n",
            "INFO:tensorflow:loss = 11.792509, step = 2301 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 527.651\n",
            "INFO:tensorflow:loss = 25.221762, step = 2401 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.275\n",
            "INFO:tensorflow:loss = 24.23129, step = 2501 (0.181 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.229\n",
            "INFO:tensorflow:loss = 17.798634, step = 2601 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.722\n",
            "INFO:tensorflow:loss = 32.080936, step = 2701 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 571.307\n",
            "INFO:tensorflow:loss = 17.583822, step = 2801 (0.175 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.121\n",
            "INFO:tensorflow:loss = 31.967037, step = 2901 (0.183 sec)\n",
            "INFO:tensorflow:global_step/sec: 523.317\n",
            "INFO:tensorflow:loss = 22.32011, step = 3001 (0.190 sec)\n",
            "INFO:tensorflow:global_step/sec: 550.703\n",
            "INFO:tensorflow:loss = 37.39518, step = 3101 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 572.688\n",
            "INFO:tensorflow:loss = 25.957493, step = 3201 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 566.232\n",
            "INFO:tensorflow:loss = 26.904009, step = 3301 (0.177 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.825\n",
            "INFO:tensorflow:loss = 23.561697, step = 3401 (0.179 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.093\n",
            "INFO:tensorflow:loss = 41.709282, step = 3501 (0.174 sec)\n",
            "INFO:tensorflow:global_step/sec: 511.894\n",
            "INFO:tensorflow:loss = 30.17249, step = 3601 (0.195 sec)\n",
            "INFO:tensorflow:global_step/sec: 568.088\n",
            "INFO:tensorflow:loss = 32.697536, step = 3701 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 556.075\n",
            "INFO:tensorflow:loss = 26.003548, step = 3801 (0.180 sec)\n",
            "INFO:tensorflow:global_step/sec: 542.19\n",
            "INFO:tensorflow:loss = 13.721317, step = 3901 (0.185 sec)\n",
            "INFO:tensorflow:global_step/sec: 562.24\n",
            "INFO:tensorflow:loss = 22.145702, step = 4001 (0.178 sec)\n",
            "INFO:tensorflow:global_step/sec: 565.01\n",
            "INFO:tensorflow:loss = 13.128688, step = 4101 (0.176 sec)\n",
            "INFO:tensorflow:global_step/sec: 530.42\n",
            "INFO:tensorflow:loss = 16.036428, step = 4201 (0.192 sec)\n",
            "INFO:tensorflow:global_step/sec: 567.369\n",
            "INFO:tensorflow:loss = 32.52892, step = 4301 (0.172 sec)\n",
            "INFO:tensorflow:global_step/sec: 584.967\n",
            "INFO:tensorflow:loss = 17.694063, step = 4401 (0.171 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.553\n",
            "INFO:tensorflow:loss = 21.488583, step = 4501 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 593.694\n",
            "INFO:tensorflow:loss = 24.712646, step = 4601 (0.170 sec)\n",
            "INFO:tensorflow:global_step/sec: 599.783\n",
            "INFO:tensorflow:loss = 14.35133, step = 4701 (0.166 sec)\n",
            "INFO:tensorflow:global_step/sec: 547.256\n",
            "INFO:tensorflow:loss = 16.118498, step = 4801 (0.186 sec)\n",
            "INFO:tensorflow:global_step/sec: 569.1\n",
            "INFO:tensorflow:loss = 16.026243, step = 4901 (0.173 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into /tmp/tfmodels/mnist_estimators/linear_1534533340/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 16.408869.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.canned.linear.LinearClassifier at 0x7f1a2e1ab6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "6TadMC9BTCTd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Once we've trained the model, we'll run the evaluate() method, which uses the trained model. To do this, it loads the most recent checkpointed model info available. The model checkpoint(s) are generated during the training process.\n"
      ]
    },
    {
      "metadata": {
        "id": "m0y3ak65TCTe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "3a8cd3d1-f6f4-423d-de7d-4d09d42e127a"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "eval_input = lambda: eval_input_fn(\n",
        "    DATA_DIR,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "results = linear_classifier.evaluate(input_fn=eval_input)\n",
        "print(results)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz to /tmp/tmp6bivXm.gz\n",
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmppce663.gz\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-08-17-19:16:25\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tfmodels/mnist_estimators/linear_1534533340/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-08-17-19:16:27\n",
            "INFO:tensorflow:Saving dict for global step 5000: accuracy = 0.9291, average_loss = 0.26726565, global_step = 5000, loss = 26.726564\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: /tmp/tfmodels/mnist_estimators/linear_1534533340/model.ckpt-5000\n",
            "{'average_loss': 0.26726565, 'accuracy': 0.9291, 'global_step': 5000, 'loss': 26.726564}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s1jCXB9sTCTk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "(Note that the model accuracy is not great... we'll get back to that).\n",
        "\n",
        "We can also use the model to make a few predictions.   \n",
        "Note: If you wanted to actually deploy and serve the model, in order to support scalable predictions, you'd want to export it in a specific `SavedModel` format.  We'll get to that in a later example."
      ]
    },
    {
      "metadata": {
        "id": "p97yBufJTCTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "5652a63f-85db-4d97-e53f-83cb3d4542a5"
      },
      "cell_type": "code",
      "source": [
        "# predictions\n",
        "\n",
        "def predict_input_fn():\n",
        "  features = dataset.test(DATA_DIR).take(5).batch(batch_size=1).make_one_shot_iterator().get_next()\n",
        "  return {'pixels': features[0]}, features[1]\n",
        "\n",
        "predictions = linear_classifier.predict(input_fn=predict_input_fn)\n",
        "\n",
        "for prediction in predictions:\n",
        "    print(\"Predictions:    {} with probabilities {}\\n\".format(\n",
        "        prediction[\"classes\"], prediction[\"probabilities\"]))  \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tfmodels/mnist_estimators/linear_1534533340/model.ckpt-5000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Predictions:    ['7'] with probabilities [3.0591463e-07 1.0422642e-13 1.2444417e-06 3.0422709e-03 6.7160741e-08\n",
            " 1.0907888e-05 8.7714992e-12 9.9676764e-01 9.1745251e-06 1.6835738e-04]\n",
            "\n",
            "Predictions:    ['2'] with probabilities [4.7198613e-05 7.5383684e-07 9.9194664e-01 1.4328808e-04 4.0119395e-17\n",
            " 2.6218526e-03 5.2268622e-03 1.2350450e-21 1.3528743e-05 4.4825275e-17]\n",
            "\n",
            "Predictions:    ['1'] with probabilities [1.9050948e-07 9.8389971e-01 9.9343723e-03 1.3205970e-03 6.6517117e-05\n",
            " 7.1012176e-04 5.7844806e-04 5.0967117e-04 2.8752431e-03 1.0504787e-04]\n",
            "\n",
            "Predictions:    ['0'] with probabilities [9.9992871e-01 1.4602835e-12 2.4637824e-05 8.2680185e-07 8.0468592e-09\n",
            " 7.3336664e-06 3.2577092e-05 8.2377090e-07 3.8738840e-06 1.2251439e-06]\n",
            "\n",
            "Predictions:    ['4'] with probabilities [2.4297394e-04 3.4627941e-08 1.3041440e-03 7.4612904e-06 9.7151268e-01\n",
            " 4.9788712e-05 1.0169104e-03 8.5668050e-04 1.6257506e-03 2.3383619e-02]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-upYUsE0TCTn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1342
        },
        "outputId": "04ab0b79-645c-48cc-fc47-9ee29da6428d"
      },
      "cell_type": "code",
      "source": [
        "# Bonus: What are the labels for these predictions?\n",
        "# This will fail if matplotlib is not installed. You can just skip it if so.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "pred_next_item = dataset.test(DATA_DIR).take(5).batch(batch_size=1).make_one_shot_iterator().get_next()\n",
        "sess =  tf.Session()\n",
        "while True:\n",
        "  try:\n",
        "    item = sess.run(pred_next_item)\n",
        "    pred_label = item[1]\n",
        "    pred_image = item[0]\n",
        "    print(\"label: %s\" % pred_label)\n",
        "    sample = np.reshape(pred_image, (28,28))\n",
        "    plt.figure()\n",
        "    plt.imshow(sample, 'gray')\n",
        "  except tf.errors.OutOfRangeError:\n",
        "    break"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label: [7]\n",
            "label: [2]\n",
            "label: [1]\n",
            "label: [0]\n",
            "label: [4]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nupSB/wclp6FycBcGXAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a1f4d3a90>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a2279b990>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAhZdSsCiSwlYdCkBiy4l8H/HxeHMKACFwgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a1f39f950>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAVdJAAFXSQABV0kAAVdJAAFXSSA/wekK9vL6EXnrQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a1f3f0810>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAfw/QMRSOrzRSfoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a1f4e1790>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "5anZa3sGTCTs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## DNNClassifier: try a Deep Neural Net on the same task\n",
        "\n",
        "Next, let's see if a Deep Neural Net, with multiple hidden layers, does better at classification of these images.\n",
        "We'll use a [`DNNClassifier`](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) with multiple hidden layers.\n",
        "\n",
        "First, do some imports and set some variables:"
      ]
    },
    {
      "metadata": {
        "id": "EhyU7qp7TCTt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "DATA_DIR = \"/tmp/MNIST_data\"\n",
        "NUM_STEPS = 15000\n",
        "BATCH_SIZE = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mL4uAiJpTCTx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we'll define a `DNNClassifier`, and run its `train()` method, which will train the model. Again note that we didn't need to explicitly define a model graph or a training loop ourselves. \n",
        "\n",
        "You'll notice that this code looks much the same as that above, aside from a couple additional parameters when defining the model.\n",
        "We can use the same train and eval input functions as above.\n"
      ]
    },
    {
      "metadata": {
        "id": "AZ-tKP4pTCTz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "First, let's try training the DNNClassifier with a .1 learning rate."
      ]
    },
    {
      "metadata": {
        "id": "bG7i-yx4TCT1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5341
        },
        "outputId": "9b672902-9435-42d6-fe59-59b408128338"
      },
      "cell_type": "code",
      "source": [
        "feature_columns = [tf.feature_column.numeric_column(\n",
        "    \"pixels\", shape=784)]\n",
        "\n",
        "LR = .1\n",
        "\n",
        "dnn_classifier = tf.estimator.DNNClassifier(\n",
        "        feature_columns=feature_columns,\n",
        "        n_classes=10,\n",
        "        hidden_units=[128, 32], #hidden layer, now 2 layers, relu is default\n",
        "        optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=LR),\n",
        "        model_dir=get_new_path(\"dnn\")\n",
        "    )\n",
        "\n",
        "dnn_classifier.train(input_fn=train_input, steps=NUM_STEPS)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/tfmodels/mnist_estimators/dnn_1534533492\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1a227bb510>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tfmodels/mnist_estimators/dnn_1534533492', '_train_distribute': None, '_save_summary_steps': 100}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tfmodels/mnist_estimators/dnn_1534533492/model.ckpt.\n",
            "INFO:tensorflow:loss = 248.82869, step = 1\n",
            "INFO:tensorflow:global_step/sec: 66.1182\n",
            "INFO:tensorflow:loss = 38.33029, step = 101 (1.518 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.571\n",
            "INFO:tensorflow:loss = 23.858538, step = 201 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.419\n",
            "INFO:tensorflow:loss = 22.801687, step = 301 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 370.716\n",
            "INFO:tensorflow:loss = 15.806195, step = 401 (0.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.018\n",
            "INFO:tensorflow:loss = 20.585678, step = 501 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.021\n",
            "INFO:tensorflow:loss = 19.619984, step = 601 (0.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.98\n",
            "INFO:tensorflow:loss = 7.695056, step = 701 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 371.909\n",
            "INFO:tensorflow:loss = 12.840355, step = 801 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.852\n",
            "INFO:tensorflow:loss = 6.105495, step = 901 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 366.565\n",
            "INFO:tensorflow:loss = 9.443426, step = 1001 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.049\n",
            "INFO:tensorflow:loss = 11.647556, step = 1101 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.998\n",
            "INFO:tensorflow:loss = 3.3101501, step = 1201 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 373.56\n",
            "INFO:tensorflow:loss = 8.780157, step = 1301 (0.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 397.109\n",
            "INFO:tensorflow:loss = 12.027931, step = 1401 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.201\n",
            "INFO:tensorflow:loss = 10.978105, step = 1501 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.336\n",
            "INFO:tensorflow:loss = 6.0558214, step = 1601 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.279\n",
            "INFO:tensorflow:loss = 3.8892753, step = 1701 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.51\n",
            "INFO:tensorflow:loss = 3.522327, step = 1801 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.621\n",
            "INFO:tensorflow:loss = 8.844828, step = 1901 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.995\n",
            "INFO:tensorflow:loss = 8.058349, step = 2001 (0.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.158\n",
            "INFO:tensorflow:loss = 1.8255763, step = 2101 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 388.271\n",
            "INFO:tensorflow:loss = 15.036012, step = 2201 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 394.28\n",
            "INFO:tensorflow:loss = 8.106334, step = 2301 (0.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.262\n",
            "INFO:tensorflow:loss = 2.9089568, step = 2401 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.867\n",
            "INFO:tensorflow:loss = 6.3423877, step = 2501 (0.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.782\n",
            "INFO:tensorflow:loss = 3.0037193, step = 2601 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 400.606\n",
            "INFO:tensorflow:loss = 7.429798, step = 2701 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.778\n",
            "INFO:tensorflow:loss = 12.062753, step = 2801 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.91\n",
            "INFO:tensorflow:loss = 3.3883512, step = 2901 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 349.05\n",
            "INFO:tensorflow:loss = 4.5585065, step = 3001 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.41\n",
            "INFO:tensorflow:loss = 3.657215, step = 3101 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.474\n",
            "INFO:tensorflow:loss = 9.990985, step = 3201 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.87\n",
            "INFO:tensorflow:loss = 13.283268, step = 3301 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 392.822\n",
            "INFO:tensorflow:loss = 2.2973, step = 3401 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 388.404\n",
            "INFO:tensorflow:loss = 14.305463, step = 3501 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.254\n",
            "INFO:tensorflow:loss = 2.2916205, step = 3601 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.91\n",
            "INFO:tensorflow:loss = 6.23291, step = 3701 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.3\n",
            "INFO:tensorflow:loss = 2.2468953, step = 3801 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 394.706\n",
            "INFO:tensorflow:loss = 4.645555, step = 3901 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.746\n",
            "INFO:tensorflow:loss = 3.715291, step = 4001 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.526\n",
            "INFO:tensorflow:loss = 4.805543, step = 4101 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.931\n",
            "INFO:tensorflow:loss = 1.8249544, step = 4201 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.097\n",
            "INFO:tensorflow:loss = 3.1280737, step = 4301 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 377.332\n",
            "INFO:tensorflow:loss = 5.9765906, step = 4401 (0.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.137\n",
            "INFO:tensorflow:loss = 4.40326, step = 4501 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.856\n",
            "INFO:tensorflow:loss = 3.0319083, step = 4601 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 381.832\n",
            "INFO:tensorflow:loss = 4.8743258, step = 4701 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.002\n",
            "INFO:tensorflow:loss = 2.6529636, step = 4801 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.149\n",
            "INFO:tensorflow:loss = 1.9710418, step = 4901 (0.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 393.159\n",
            "INFO:tensorflow:loss = 3.0617518, step = 5001 (0.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.697\n",
            "INFO:tensorflow:loss = 2.614876, step = 5101 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.985\n",
            "INFO:tensorflow:loss = 6.7642574, step = 5201 (0.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.578\n",
            "INFO:tensorflow:loss = 1.7277467, step = 5301 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 340.77\n",
            "INFO:tensorflow:loss = 1.5986693, step = 5401 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.909\n",
            "INFO:tensorflow:loss = 2.1483035, step = 5501 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.469\n",
            "INFO:tensorflow:loss = 2.3686662, step = 5601 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.917\n",
            "INFO:tensorflow:loss = 0.6757809, step = 5701 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 381.813\n",
            "INFO:tensorflow:loss = 1.3605735, step = 5801 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.35\n",
            "INFO:tensorflow:loss = 3.399326, step = 5901 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.483\n",
            "INFO:tensorflow:loss = 1.90456, step = 6001 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.136\n",
            "INFO:tensorflow:loss = 2.1840878, step = 6101 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 395.444\n",
            "INFO:tensorflow:loss = 1.6624411, step = 6201 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.934\n",
            "INFO:tensorflow:loss = 5.8982406, step = 6301 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.713\n",
            "INFO:tensorflow:loss = 0.9422246, step = 6401 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.654\n",
            "INFO:tensorflow:loss = 1.8455335, step = 6501 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.184\n",
            "INFO:tensorflow:loss = 9.695271, step = 6601 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.824\n",
            "INFO:tensorflow:loss = 1.6836051, step = 6701 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 370.957\n",
            "INFO:tensorflow:loss = 1.5390363, step = 6801 (0.268 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.965\n",
            "INFO:tensorflow:loss = 6.0896883, step = 6901 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.442\n",
            "INFO:tensorflow:loss = 8.528194, step = 7001 (0.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.931\n",
            "INFO:tensorflow:loss = 1.1379833, step = 7101 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.713\n",
            "INFO:tensorflow:loss = 6.222559, step = 7201 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 381.381\n",
            "INFO:tensorflow:loss = 4.0382037, step = 7301 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 392.171\n",
            "INFO:tensorflow:loss = 5.7196827, step = 7401 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.655\n",
            "INFO:tensorflow:loss = 2.822901, step = 7501 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 392.049\n",
            "INFO:tensorflow:loss = 1.1709077, step = 7601 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.371\n",
            "INFO:tensorflow:loss = 2.2527454, step = 7701 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.478\n",
            "INFO:tensorflow:loss = 1.7402755, step = 7801 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 378.451\n",
            "INFO:tensorflow:loss = 1.4331892, step = 7901 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 387.92\n",
            "INFO:tensorflow:loss = 0.28333518, step = 8001 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.897\n",
            "INFO:tensorflow:loss = 0.4404741, step = 8101 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.665\n",
            "INFO:tensorflow:loss = 1.8766217, step = 8201 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.681\n",
            "INFO:tensorflow:loss = 1.461207, step = 8301 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.631\n",
            "INFO:tensorflow:loss = 0.9236744, step = 8401 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.612\n",
            "INFO:tensorflow:loss = 1.8734567, step = 8501 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.087\n",
            "INFO:tensorflow:loss = 1.9403125, step = 8601 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.22\n",
            "INFO:tensorflow:loss = 6.150106, step = 8701 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.416\n",
            "INFO:tensorflow:loss = 1.2646571, step = 8801 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.373\n",
            "INFO:tensorflow:loss = 0.9746733, step = 8901 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.992\n",
            "INFO:tensorflow:loss = 0.28448433, step = 9001 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 381.076\n",
            "INFO:tensorflow:loss = 0.91127956, step = 9101 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 376.347\n",
            "INFO:tensorflow:loss = 2.7742836, step = 9201 (0.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.173\n",
            "INFO:tensorflow:loss = 0.43792233, step = 9301 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 381.915\n",
            "INFO:tensorflow:loss = 0.19434239, step = 9401 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 388.691\n",
            "INFO:tensorflow:loss = 0.4398131, step = 9501 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.833\n",
            "INFO:tensorflow:loss = 0.70274365, step = 9601 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 369.393\n",
            "INFO:tensorflow:loss = 0.30979487, step = 9701 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.343\n",
            "INFO:tensorflow:loss = 10.027344, step = 9801 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.409\n",
            "INFO:tensorflow:loss = 0.592383, step = 9901 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 376.828\n",
            "INFO:tensorflow:loss = 0.36778727, step = 10001 (0.268 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.014\n",
            "INFO:tensorflow:loss = 0.23472492, step = 10101 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.001\n",
            "INFO:tensorflow:loss = 1.274768, step = 10201 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.213\n",
            "INFO:tensorflow:loss = 1.2017202, step = 10301 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.999\n",
            "INFO:tensorflow:loss = 0.24116479, step = 10401 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.973\n",
            "INFO:tensorflow:loss = 0.36819774, step = 10501 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.592\n",
            "INFO:tensorflow:loss = 0.42036816, step = 10601 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.933\n",
            "INFO:tensorflow:loss = 0.40408665, step = 10701 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.345\n",
            "INFO:tensorflow:loss = 0.79690135, step = 10801 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.693\n",
            "INFO:tensorflow:loss = 0.3130313, step = 10901 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.295\n",
            "INFO:tensorflow:loss = 0.7949593, step = 11001 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.172\n",
            "INFO:tensorflow:loss = 0.65148854, step = 11101 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 387.606\n",
            "INFO:tensorflow:loss = 0.33450657, step = 11201 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.475\n",
            "INFO:tensorflow:loss = 0.025070209, step = 11301 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.77\n",
            "INFO:tensorflow:loss = 0.31930426, step = 11401 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.745\n",
            "INFO:tensorflow:loss = 0.2605228, step = 11501 (0.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.043\n",
            "INFO:tensorflow:loss = 0.67233586, step = 11601 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.468\n",
            "INFO:tensorflow:loss = 0.27416474, step = 11701 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.799\n",
            "INFO:tensorflow:loss = 1.1458277, step = 11801 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.247\n",
            "INFO:tensorflow:loss = 7.6780257, step = 11901 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.809\n",
            "INFO:tensorflow:loss = 0.2654342, step = 12001 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.961\n",
            "INFO:tensorflow:loss = 0.13396555, step = 12101 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.152\n",
            "INFO:tensorflow:loss = 0.28768337, step = 12201 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 394.154\n",
            "INFO:tensorflow:loss = 0.265817, step = 12301 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.541\n",
            "INFO:tensorflow:loss = 0.24139601, step = 12401 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.478\n",
            "INFO:tensorflow:loss = 0.32727137, step = 12501 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 358.868\n",
            "INFO:tensorflow:loss = 0.06820244, step = 12601 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.461\n",
            "INFO:tensorflow:loss = 0.333772, step = 12701 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.364\n",
            "INFO:tensorflow:loss = 0.46611238, step = 12801 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.58\n",
            "INFO:tensorflow:loss = 0.1551022, step = 12901 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.127\n",
            "INFO:tensorflow:loss = 0.095696196, step = 13001 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 388.229\n",
            "INFO:tensorflow:loss = 0.14534926, step = 13101 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.01\n",
            "INFO:tensorflow:loss = 0.29623634, step = 13201 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.868\n",
            "INFO:tensorflow:loss = 1.3603271, step = 13301 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 392.011\n",
            "INFO:tensorflow:loss = 0.49124846, step = 13401 (0.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.799\n",
            "INFO:tensorflow:loss = 0.27302507, step = 13501 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 402.769\n",
            "INFO:tensorflow:loss = 0.90165806, step = 13601 (0.248 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.223\n",
            "INFO:tensorflow:loss = 0.1802365, step = 13701 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.95\n",
            "INFO:tensorflow:loss = 0.34252304, step = 13801 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.114\n",
            "INFO:tensorflow:loss = 0.2000728, step = 13901 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 394.435\n",
            "INFO:tensorflow:loss = 0.34997222, step = 14001 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 397.84\n",
            "INFO:tensorflow:loss = 0.38051146, step = 14101 (0.251 sec)\n",
            "INFO:tensorflow:global_step/sec: 388.482\n",
            "INFO:tensorflow:loss = 0.40937838, step = 14201 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 388.549\n",
            "INFO:tensorflow:loss = 0.29964057, step = 14301 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 367.982\n",
            "INFO:tensorflow:loss = 0.13445513, step = 14401 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 392.011\n",
            "INFO:tensorflow:loss = 0.50233495, step = 14501 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.638\n",
            "INFO:tensorflow:loss = 0.5318743, step = 14601 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.71\n",
            "INFO:tensorflow:loss = 0.54322064, step = 14701 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.629\n",
            "INFO:tensorflow:loss = 0.62267566, step = 14801 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 400.06\n",
            "INFO:tensorflow:loss = 0.5698688, step = 14901 (0.249 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 15000 into /tmp/tfmodels/mnist_estimators/dnn_1534533492/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.60309863.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f1a1f4bd250>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "id": "VYFRRL25TCT3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we'll evaluate the trained model. Note the accuracy."
      ]
    },
    {
      "metadata": {
        "id": "BpODy8C9TCT4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5dc85223-20b3-4590-9d0f-ec7ac765ea51"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "\n",
        "results = dnn_classifier.evaluate(input_fn=eval_input)\n",
        "print(results)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-08-17-19:19:45\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tfmodels/mnist_estimators/dnn_1534533492/model.ckpt-15000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-08-17-19:19:47\n",
            "INFO:tensorflow:Saving dict for global step 15000: accuracy = 0.9764, average_loss = 0.1165063, global_step = 15000, loss = 11.65063\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: /tmp/tfmodels/mnist_estimators/dnn_1534533492/model.ckpt-15000\n",
            "{'average_loss': 0.1165063, 'accuracy': 0.9764, 'global_step': 15000, 'loss': 11.65063}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "64L7a90ITCT6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Next, let's try using a .5 learning rate."
      ]
    },
    {
      "metadata": {
        "id": "1ysujNhtVi9G",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Worse results with bigger adjustment to weights (adjusted during back prop). Model is having trouble adjusting."
      ]
    },
    {
      "metadata": {
        "id": "0UPXaHp4TCT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5341
        },
        "outputId": "c8fb4ffb-1255-42e2-dfe6-346750eaf08d"
      },
      "cell_type": "code",
      "source": [
        "LR5 = .5\n",
        "\n",
        "dnn_classifier5 = tf.estimator.DNNClassifier(\n",
        "        feature_columns=feature_columns,\n",
        "        n_classes=10,\n",
        "        hidden_units=[128, 32],\n",
        "        optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=LR5),\n",
        "        model_dir=get_new_path(\"dnn5\")\n",
        "    )\n",
        "\n",
        "dnn_classifier5.train(input_fn=train_input, steps=NUM_STEPS)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/tfmodels/mnist_estimators/dnn5_1534533640\n",
            "INFO:tensorflow:Using default config.\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1a1f511050>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tfmodels/mnist_estimators/dnn5_1534533640', '_train_distribute': None, '_save_summary_steps': 100}\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tfmodels/mnist_estimators/dnn5_1534533640/model.ckpt.\n",
            "INFO:tensorflow:loss = 248.34062, step = 1\n",
            "INFO:tensorflow:global_step/sec: 67.7547\n",
            "INFO:tensorflow:loss = 230.035, step = 101 (1.481 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.53\n",
            "INFO:tensorflow:loss = 231.1049, step = 201 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.615\n",
            "INFO:tensorflow:loss = 232.14886, step = 301 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 393.153\n",
            "INFO:tensorflow:loss = 230.43027, step = 401 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.04\n",
            "INFO:tensorflow:loss = 230.20192, step = 501 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.839\n",
            "INFO:tensorflow:loss = 231.34706, step = 601 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.863\n",
            "INFO:tensorflow:loss = 231.01694, step = 701 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 329.317\n",
            "INFO:tensorflow:loss = 230.56815, step = 801 (0.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.984\n",
            "INFO:tensorflow:loss = 231.05344, step = 901 (0.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.629\n",
            "INFO:tensorflow:loss = 229.86133, step = 1001 (0.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.897\n",
            "INFO:tensorflow:loss = 230.72905, step = 1101 (0.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.746\n",
            "INFO:tensorflow:loss = 230.47891, step = 1201 (0.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 342.337\n",
            "INFO:tensorflow:loss = 230.59033, step = 1301 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 329.837\n",
            "INFO:tensorflow:loss = 229.40376, step = 1401 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.596\n",
            "INFO:tensorflow:loss = 230.08665, step = 1501 (0.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.252\n",
            "INFO:tensorflow:loss = 231.41852, step = 1601 (0.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.239\n",
            "INFO:tensorflow:loss = 230.49155, step = 1701 (0.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.276\n",
            "INFO:tensorflow:loss = 230.55028, step = 1801 (0.326 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.192\n",
            "INFO:tensorflow:loss = 229.60469, step = 1901 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.591\n",
            "INFO:tensorflow:loss = 229.68979, step = 2001 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.232\n",
            "INFO:tensorflow:loss = 229.3111, step = 2101 (0.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.795\n",
            "INFO:tensorflow:loss = 230.06793, step = 2201 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.908\n",
            "INFO:tensorflow:loss = 229.48863, step = 2301 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.953\n",
            "INFO:tensorflow:loss = 230.26234, step = 2401 (0.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 329.756\n",
            "INFO:tensorflow:loss = 231.1867, step = 2501 (0.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.774\n",
            "INFO:tensorflow:loss = 230.04352, step = 2601 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 324.428\n",
            "INFO:tensorflow:loss = 230.67216, step = 2701 (0.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.099\n",
            "INFO:tensorflow:loss = 229.66365, step = 2801 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 331.318\n",
            "INFO:tensorflow:loss = 230.7294, step = 2901 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.681\n",
            "INFO:tensorflow:loss = 229.55705, step = 3001 (0.323 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.114\n",
            "INFO:tensorflow:loss = 230.20967, step = 3101 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.531\n",
            "INFO:tensorflow:loss = 229.95166, step = 3201 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 332.259\n",
            "INFO:tensorflow:loss = 228.86424, step = 3301 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.091\n",
            "INFO:tensorflow:loss = 229.68414, step = 3401 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.117\n",
            "INFO:tensorflow:loss = 231.0802, step = 3501 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 311.802\n",
            "INFO:tensorflow:loss = 230.35022, step = 3601 (0.320 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.748\n",
            "INFO:tensorflow:loss = 230.91301, step = 3701 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.962\n",
            "INFO:tensorflow:loss = 229.12503, step = 3801 (0.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.85\n",
            "INFO:tensorflow:loss = 229.99165, step = 3901 (0.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.118\n",
            "INFO:tensorflow:loss = 230.23541, step = 4001 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.489\n",
            "INFO:tensorflow:loss = 230.1187, step = 4101 (0.294 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.355\n",
            "INFO:tensorflow:loss = 231.28497, step = 4201 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.89\n",
            "INFO:tensorflow:loss = 230.63678, step = 4301 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.548\n",
            "INFO:tensorflow:loss = 230.7204, step = 4401 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.848\n",
            "INFO:tensorflow:loss = 230.09128, step = 4501 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.769\n",
            "INFO:tensorflow:loss = 230.483, step = 4601 (0.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.492\n",
            "INFO:tensorflow:loss = 230.14995, step = 4701 (0.287 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.553\n",
            "INFO:tensorflow:loss = 230.07964, step = 4801 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.425\n",
            "INFO:tensorflow:loss = 229.31499, step = 4901 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.097\n",
            "INFO:tensorflow:loss = 229.54868, step = 5001 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.167\n",
            "INFO:tensorflow:loss = 231.14142, step = 5101 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.535\n",
            "INFO:tensorflow:loss = 229.60223, step = 5201 (0.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.945\n",
            "INFO:tensorflow:loss = 230.27762, step = 5301 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 319.514\n",
            "INFO:tensorflow:loss = 229.08289, step = 5401 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 332.038\n",
            "INFO:tensorflow:loss = 230.88748, step = 5501 (0.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 347.836\n",
            "INFO:tensorflow:loss = 230.63602, step = 5601 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.515\n",
            "INFO:tensorflow:loss = 229.76875, step = 5701 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.326\n",
            "INFO:tensorflow:loss = 230.17926, step = 5801 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 368.354\n",
            "INFO:tensorflow:loss = 230.3048, step = 5901 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.684\n",
            "INFO:tensorflow:loss = 229.862, step = 6001 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.923\n",
            "INFO:tensorflow:loss = 230.25989, step = 6101 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 367.611\n",
            "INFO:tensorflow:loss = 230.73532, step = 6201 (0.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 368.926\n",
            "INFO:tensorflow:loss = 230.55257, step = 6301 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.628\n",
            "INFO:tensorflow:loss = 229.7948, step = 6401 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 387.133\n",
            "INFO:tensorflow:loss = 229.72646, step = 6501 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.61\n",
            "INFO:tensorflow:loss = 231.5876, step = 6601 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.446\n",
            "INFO:tensorflow:loss = 229.251, step = 6701 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 394.636\n",
            "INFO:tensorflow:loss = 230.21144, step = 6801 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.111\n",
            "INFO:tensorflow:loss = 230.61751, step = 6901 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.102\n",
            "INFO:tensorflow:loss = 229.91669, step = 7001 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.706\n",
            "INFO:tensorflow:loss = 230.50352, step = 7101 (0.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.434\n",
            "INFO:tensorflow:loss = 230.08429, step = 7201 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.208\n",
            "INFO:tensorflow:loss = 230.26389, step = 7301 (0.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.217\n",
            "INFO:tensorflow:loss = 229.90536, step = 7401 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.179\n",
            "INFO:tensorflow:loss = 229.58113, step = 7501 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.789\n",
            "INFO:tensorflow:loss = 230.24208, step = 7601 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 367.628\n",
            "INFO:tensorflow:loss = 229.23615, step = 7701 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 339.489\n",
            "INFO:tensorflow:loss = 229.96535, step = 7801 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.124\n",
            "INFO:tensorflow:loss = 230.46524, step = 7901 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.874\n",
            "INFO:tensorflow:loss = 230.12384, step = 8001 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.82\n",
            "INFO:tensorflow:loss = 230.24835, step = 8101 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 368.144\n",
            "INFO:tensorflow:loss = 230.30165, step = 8201 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.113\n",
            "INFO:tensorflow:loss = 231.17075, step = 8301 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 334.36\n",
            "INFO:tensorflow:loss = 231.708, step = 8401 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.493\n",
            "INFO:tensorflow:loss = 230.1238, step = 8501 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 367.948\n",
            "INFO:tensorflow:loss = 230.7919, step = 8601 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.952\n",
            "INFO:tensorflow:loss = 230.13992, step = 8701 (0.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.19\n",
            "INFO:tensorflow:loss = 230.52905, step = 8801 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.22\n",
            "INFO:tensorflow:loss = 229.55276, step = 8901 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.746\n",
            "INFO:tensorflow:loss = 230.40298, step = 9001 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 358.436\n",
            "INFO:tensorflow:loss = 230.11784, step = 9101 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 368.156\n",
            "INFO:tensorflow:loss = 230.26706, step = 9201 (0.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.313\n",
            "INFO:tensorflow:loss = 230.32755, step = 9301 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.054\n",
            "INFO:tensorflow:loss = 230.34393, step = 9401 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 393.125\n",
            "INFO:tensorflow:loss = 231.12924, step = 9501 (0.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.495\n",
            "INFO:tensorflow:loss = 230.56631, step = 9601 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.851\n",
            "INFO:tensorflow:loss = 230.50142, step = 9701 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.366\n",
            "INFO:tensorflow:loss = 229.96274, step = 9801 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.681\n",
            "INFO:tensorflow:loss = 229.92734, step = 9901 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.622\n",
            "INFO:tensorflow:loss = 229.8614, step = 10001 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 366.855\n",
            "INFO:tensorflow:loss = 230.04521, step = 10101 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 342.454\n",
            "INFO:tensorflow:loss = 229.84671, step = 10201 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.21\n",
            "INFO:tensorflow:loss = 230.93195, step = 10301 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 356\n",
            "INFO:tensorflow:loss = 230.10164, step = 10401 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 358.984\n",
            "INFO:tensorflow:loss = 229.27582, step = 10501 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 366.773\n",
            "INFO:tensorflow:loss = 228.46846, step = 10601 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 381.726\n",
            "INFO:tensorflow:loss = 230.40446, step = 10701 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.135\n",
            "INFO:tensorflow:loss = 229.11688, step = 10801 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.122\n",
            "INFO:tensorflow:loss = 229.46974, step = 10901 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 358.195\n",
            "INFO:tensorflow:loss = 230.03334, step = 11001 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.216\n",
            "INFO:tensorflow:loss = 229.98618, step = 11101 (0.290 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.84\n",
            "INFO:tensorflow:loss = 230.75935, step = 11201 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.673\n",
            "INFO:tensorflow:loss = 230.50656, step = 11301 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.902\n",
            "INFO:tensorflow:loss = 229.77625, step = 11401 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 372.712\n",
            "INFO:tensorflow:loss = 230.53912, step = 11501 (0.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.082\n",
            "INFO:tensorflow:loss = 229.43916, step = 11601 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.811\n",
            "INFO:tensorflow:loss = 231.19499, step = 11701 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.338\n",
            "INFO:tensorflow:loss = 230.61642, step = 11801 (0.253 sec)\n",
            "INFO:tensorflow:global_step/sec: 396.626\n",
            "INFO:tensorflow:loss = 230.78587, step = 11901 (0.252 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.065\n",
            "INFO:tensorflow:loss = 230.66832, step = 12001 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 387.16\n",
            "INFO:tensorflow:loss = 230.01675, step = 12101 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.197\n",
            "INFO:tensorflow:loss = 230.23007, step = 12201 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.957\n",
            "INFO:tensorflow:loss = 230.64201, step = 12301 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.156\n",
            "INFO:tensorflow:loss = 229.76395, step = 12401 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 381.133\n",
            "INFO:tensorflow:loss = 229.24727, step = 12501 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.004\n",
            "INFO:tensorflow:loss = 229.95068, step = 12601 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.017\n",
            "INFO:tensorflow:loss = 230.23369, step = 12701 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.033\n",
            "INFO:tensorflow:loss = 231.17392, step = 12801 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.227\n",
            "INFO:tensorflow:loss = 230.00476, step = 12901 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.57\n",
            "INFO:tensorflow:loss = 230.79369, step = 13001 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 391.853\n",
            "INFO:tensorflow:loss = 229.46632, step = 13101 (0.255 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.054\n",
            "INFO:tensorflow:loss = 230.2232, step = 13201 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.459\n",
            "INFO:tensorflow:loss = 228.93347, step = 13301 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.408\n",
            "INFO:tensorflow:loss = 230.60431, step = 13401 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.718\n",
            "INFO:tensorflow:loss = 230.11662, step = 13501 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.591\n",
            "INFO:tensorflow:loss = 229.99878, step = 13601 (0.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.892\n",
            "INFO:tensorflow:loss = 230.83162, step = 13701 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.621\n",
            "INFO:tensorflow:loss = 229.84775, step = 13801 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.285\n",
            "INFO:tensorflow:loss = 229.86595, step = 13901 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 380.725\n",
            "INFO:tensorflow:loss = 230.01062, step = 14001 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 385.732\n",
            "INFO:tensorflow:loss = 230.48792, step = 14101 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.701\n",
            "INFO:tensorflow:loss = 229.7104, step = 14201 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 381.645\n",
            "INFO:tensorflow:loss = 230.07558, step = 14301 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.986\n",
            "INFO:tensorflow:loss = 230.71939, step = 14401 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.221\n",
            "INFO:tensorflow:loss = 230.2887, step = 14501 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.549\n",
            "INFO:tensorflow:loss = 229.96674, step = 14601 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.387\n",
            "INFO:tensorflow:loss = 230.59854, step = 14701 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 378.6\n",
            "INFO:tensorflow:loss = 230.40027, step = 14801 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.502\n",
            "INFO:tensorflow:loss = 230.20407, step = 14901 (0.263 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 15000 into /tmp/tfmodels/mnist_estimators/dnn5_1534533640/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 230.06238.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f1a1f511810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "Umhm1DywTCT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "d475ae08-eefc-4df6-f662-d06417edfa4d"
      },
      "cell_type": "code",
      "source": [
        "# Evaluate\n",
        "results = dnn_classifier5.evaluate(input_fn=eval_input)\n",
        "print(results)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-08-17-19:23:07\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tfmodels/mnist_estimators/dnn5_1534533640/model.ckpt-15000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-08-17-19:23:09\n",
            "INFO:tensorflow:Saving dict for global step 15000: accuracy = 0.1135, average_loss = 2.3012064, global_step = 15000, loss = 230.12065\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: /tmp/tfmodels/mnist_estimators/dnn5_1534533640/model.ckpt-15000\n",
            "{'average_loss': 2.3012064, 'accuracy': 0.1135, 'global_step': 15000, 'loss': 230.12065}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oF3cJkqSTCUA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "To compare your results, let's start up TensorBoard! \n",
        "\n",
        "**Note**: If you're running this notebook on **colab, you will not be able to run TensorBoard from the notebook**, so you will need to skip this step.\n",
        "\n",
        "You can start it as follows in a new terminal window. (If you get a 'not found' error, make sure you've activated your virtual environment in that new window):\n",
        "\n",
        "```sh\n",
        "$ tensorboard --logdir=/tmp/tfmodels/mnist_estimators\n",
        "```\n",
        "Look for it at localhost:6006\n",
        "\n",
        "Alternately, run the following (select Kernel --> Interrupt from the menu when you're done)."
      ]
    },
    {
      "metadata": {
        "id": "LLBfjtzvTCUB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "outputId": "dac416e2-60ec-4102-a6de-2b47848fbee1"
      },
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=/tmp/tfmodels/mnist_estimators"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33mW0817 19:23:41.483645 Reloader plugin_event_accumulator.py:286] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\r\n",
            "\u001b[0mW0817 19:23:41.483644 139999811757824 plugin_event_accumulator.py:286] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\r\n",
            "\u001b[33mW0817 19:23:41.484552 Reloader plugin_event_accumulator.py:294] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\r\n",
            "\u001b[0mW0817 19:23:41.484551 139999811757824 plugin_event_accumulator.py:294] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
            "TensorBoard 1.10.0 at http://92b1be5c360d:6006 (Press CTRL+C to quit)\n",
            "\u001b[33mW0817 19:23:41.720101 Reloader plugin_event_accumulator.py:286] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
            "\u001b[0mW0817 19:23:41.720101 139999811757824 plugin_event_accumulator.py:286] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
            "\u001b[33mW0817 19:23:41.720631 Reloader plugin_event_accumulator.py:294] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
            "\u001b[0mW0817 19:23:41.720630 139999811757824 plugin_event_accumulator.py:294] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
            "\u001b[33mW0817 19:23:41.872779 Reloader plugin_event_accumulator.py:286] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
            "\u001b[0mW0817 19:23:41.872778 139999811757824 plugin_event_accumulator.py:286] Found more than one graph event per run, or there was a metagraph containing a graph_def, as well as one or more graph events.  Overwriting the graph with the newest event.\n",
            "\u001b[33mW0817 19:23:41.873446 Reloader plugin_event_accumulator.py:294] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
            "\u001b[0mW0817 19:23:41.873445 139999811757824 plugin_event_accumulator.py:294] Found more than one metagraph event per run. Overwriting the metagraph with the newest event.\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RO7HiS0JTCUM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fashion MNIST! and `tf.estimator.train_and_evaluate()`\n",
        "\n",
        "Next, let's look at our results with a data set that's harder: [Fashion-MNIST](https://github.com/zalandoresearch/fashion-mnist#get-the-data).\n",
        "\n",
        "<img src=\"https://storage.googleapis.com/amy-jo/images/fashion-mnist-sprite%20_sm.png\" width=\"40%\"\n",
        "         alt=\"Fashion MNIST\">"
      ]
    },
    {
      "metadata": {
        "id": "elUrJ9_kTCUN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If you haven't already downloaded the Fashion-MNIST files, you can do so as follows. **If you've already downloaded them, you don't need to do so again.**"
      ]
    },
    {
      "metadata": {
        "id": "uZVU8PqGTCUO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "mkdir -p fashion_mnist\n",
        "cd fashion_mnist\n",
        "wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
        "wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
        "wget http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
        "gunzip *\n",
        "cd .."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eY10hgj2TCUR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "If wget is not installed on your machine, try **replacing** the `wget` lines with:\n",
        "```\n",
        "curl -o train-images-idx3-ubyte.gz http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "curl -o train-labels-idx1-ubyte.gz http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
        "curl -o t10k-images-idx3-ubyte.gz http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
        "curl -o t10k-labels-idx1-ubyte.gz http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
        "```\n",
        "or [download directly from the site](https://github.com/zalandoresearch/fashion-mnist#get-the-data).\n",
        "\n",
        "Confirm that everything looks okay. You want the files to be **unzipped**."
      ]
    },
    {
      "metadata": {
        "id": "jJRhPoK-TCUS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%%bash\n",
        "ls -l fashion_mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PhcTnd1iTCUa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### `tf.estimator.train_and_evaluate()`\n",
        "\n",
        "TensorFlow’s version 1.4 release [introduced](https://cloud.google.com/blog/big-data/2018/02/easy-distributed-training-with-tensorflow-using-tfestimatortrain-and-evaluate-on-cloud-ml-engine) the [`tf.estimator.train_and_evaluate`](https://www.tensorflow.org/api_docs/python/tf/estimator/train_and_evaluate) function, which simplifies training, evaluation, and exporting of Estimator models. It abstracts away the details of distributed execution for training and evaluation, while also supporting consistent behavior across local/non-distributed and distributed configurations.\n",
        "\n",
        "For this example, we'll use `tf.estimator.train_and_evaluate` instead of making separate 'train' and 'evaluate' calls.\n",
        "To keep this example simple, we're not including model export.\n",
        "We'll show that in a later lab."
      ]
    },
    {
      "metadata": {
        "id": "Hb-cuJFcTCUc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "487ba91f-395a-468a-ef7e-ac5bd280bd73"
      },
      "cell_type": "code",
      "source": [
        "# edit path to directory as necessary\n",
        "FASHION_DATA_DIR = \"fashion_mnist\" \n",
        "\n",
        "train_input_fashion = lambda: train_input_fn(\n",
        "    FASHION_DATA_DIR,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "eval_input_fashion = lambda: eval_input_fn(\n",
        "    FASHION_DATA_DIR,\n",
        "    batch_size=BATCH_SIZE\n",
        ")\n",
        "\n",
        "feature_columns = [tf.feature_column.numeric_column(\n",
        "    \"pixels\", shape=784)]\n",
        "\n",
        "LR = .1\n",
        "\n",
        "run_config = tf.estimator.RunConfig()\n",
        "run_config = run_config.replace(model_dir=get_new_path(\"fashion_dnn\"))\n",
        "\n",
        "fashion_dnn_classifier = tf.estimator.DNNClassifier(\n",
        "        feature_columns=feature_columns,\n",
        "        n_classes=10,\n",
        "        hidden_units=[128, 32],\n",
        "        optimizer=tf.train.ProximalAdagradOptimizer(learning_rate=LR),\n",
        "        config=run_config\n",
        "    )\n",
        "\n",
        "train_spec = tf.estimator.TrainSpec(train_input_fashion,\n",
        "                                  max_steps=NUM_STEPS\n",
        "                                  )\n",
        "\n",
        "# While not shown here, we can also add a model 'exporter' to the EvalSpec.\n",
        "eval_spec = tf.estimator.EvalSpec(eval_input_fashion,\n",
        "                                steps=NUM_STEPS,\n",
        "                                name='fashion-eval'\n",
        "                                )\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Logging to /tmp/tfmodels/mnist_estimators/fashion_dnn_1534533961\n",
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_global_id_in_cluster': 0, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1a1d5a3610>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tfmodels/mnist_estimators/fashion_dnn_1534533961', '_train_distribute': None, '_save_summary_steps': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vS7Xen1NTCUf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Add another metric to the estimator -- *recall* -- using Tensorflow's built-in metrics."
      ]
    },
    {
      "metadata": {
        "id": "ktKa22lyTCUh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def my_recall(labels, predictions):\n",
        "  return {'recall': tf.metrics.recall(labels, predictions['class_ids'])}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hYq4mC6qTCUm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "8755b90d-bd80-49e6-9daf-2900e7778166"
      },
      "cell_type": "code",
      "source": [
        "# add the recall metric to the estimator\n",
        "fashion_dnn_classifier = tf.contrib.estimator.add_metrics(fashion_dnn_classifier, my_recall)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_task_type': 'worker', '_train_distribute': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1a1d5a3490>, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_service': None, '_num_ps_replicas': 0, '_tf_random_seed': None, '_master': '', '_device_fn': None, '_num_worker_replicas': 1, '_task_id': 0, '_log_step_count_steps': 100, '_model_dir': '/tmp/tfmodels/mnist_estimators/fashion_dnn_1534533961', '_global_id_in_cluster': 0, '_save_summary_steps': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y11Ix625TCUr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "Before running `train_and_evaluate`, try adding a *precision* metric too."
      ]
    },
    {
      "metadata": {
        "id": "XuAG7kNjTCUs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# your new code here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x-HnfNBZTCUt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5715
        },
        "outputId": "e144863b-87fb-4cf5-98df-642b6f353b01"
      },
      "cell_type": "code",
      "source": [
        "tf.estimator.train_and_evaluate(fashion_dnn_classifier,\n",
        "                                train_spec,\n",
        "                                eval_spec)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-images-idx3-ubyte.gz to /tmp/tmp5wTjJo.gz\n",
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/train-labels-idx1-ubyte.gz to /tmp/tmpSXn3as.gz\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tfmodels/mnist_estimators/fashion_dnn_1534533961/model.ckpt.\n",
            "INFO:tensorflow:loss = 242.63501, step = 1\n",
            "INFO:tensorflow:global_step/sec: 58.898\n",
            "INFO:tensorflow:loss = 32.802177, step = 101 (1.702 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.996\n",
            "INFO:tensorflow:loss = 22.262096, step = 201 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.821\n",
            "INFO:tensorflow:loss = 23.601961, step = 301 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.416\n",
            "INFO:tensorflow:loss = 24.848751, step = 401 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.19\n",
            "INFO:tensorflow:loss = 13.661766, step = 501 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 334.516\n",
            "INFO:tensorflow:loss = 25.761377, step = 601 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.732\n",
            "INFO:tensorflow:loss = 8.819298, step = 701 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.377\n",
            "INFO:tensorflow:loss = 22.00172, step = 801 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.736\n",
            "INFO:tensorflow:loss = 9.5673275, step = 901 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.801\n",
            "INFO:tensorflow:loss = 10.3966, step = 1001 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.051\n",
            "INFO:tensorflow:loss = 21.559696, step = 1101 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.358\n",
            "INFO:tensorflow:loss = 9.456194, step = 1201 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.803\n",
            "INFO:tensorflow:loss = 19.147234, step = 1301 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 367.549\n",
            "INFO:tensorflow:loss = 5.1771703, step = 1401 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 368.552\n",
            "INFO:tensorflow:loss = 13.488456, step = 1501 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.813\n",
            "INFO:tensorflow:loss = 7.150165, step = 1601 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.079\n",
            "INFO:tensorflow:loss = 22.089918, step = 1701 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.013\n",
            "INFO:tensorflow:loss = 10.354598, step = 1801 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.069\n",
            "INFO:tensorflow:loss = 10.169005, step = 1901 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.451\n",
            "INFO:tensorflow:loss = 6.1624455, step = 2001 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.243\n",
            "INFO:tensorflow:loss = 10.445764, step = 2101 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 370.939\n",
            "INFO:tensorflow:loss = 10.930321, step = 2201 (0.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 370.679\n",
            "INFO:tensorflow:loss = 11.956902, step = 2301 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 343.839\n",
            "INFO:tensorflow:loss = 16.706856, step = 2401 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.555\n",
            "INFO:tensorflow:loss = 6.432561, step = 2501 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.134\n",
            "INFO:tensorflow:loss = 6.717104, step = 2601 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 364.704\n",
            "INFO:tensorflow:loss = 11.899434, step = 2701 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 361.999\n",
            "INFO:tensorflow:loss = 8.47078, step = 2801 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.98\n",
            "INFO:tensorflow:loss = 2.358699, step = 2901 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 341.064\n",
            "INFO:tensorflow:loss = 7.947773, step = 3001 (0.293 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.74\n",
            "INFO:tensorflow:loss = 4.618363, step = 3101 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.89\n",
            "INFO:tensorflow:loss = 9.872551, step = 3201 (0.272 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.483\n",
            "INFO:tensorflow:loss = 5.1013966, step = 3301 (0.275 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.504\n",
            "INFO:tensorflow:loss = 19.415869, step = 3401 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 358.863\n",
            "INFO:tensorflow:loss = 4.890148, step = 3501 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 336.824\n",
            "INFO:tensorflow:loss = 3.7262259, step = 3601 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.37\n",
            "INFO:tensorflow:loss = 3.0624363, step = 3701 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 369.311\n",
            "INFO:tensorflow:loss = 8.809648, step = 3801 (0.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 367.131\n",
            "INFO:tensorflow:loss = 5.179798, step = 3901 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.002\n",
            "INFO:tensorflow:loss = 7.4595456, step = 4001 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.896\n",
            "INFO:tensorflow:loss = 0.44783443, step = 4101 (0.273 sec)\n",
            "INFO:tensorflow:global_step/sec: 344.944\n",
            "INFO:tensorflow:loss = 5.2533617, step = 4201 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 392.012\n",
            "INFO:tensorflow:loss = 1.0022811, step = 4301 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 386.177\n",
            "INFO:tensorflow:loss = 1.5703958, step = 4401 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.807\n",
            "INFO:tensorflow:loss = 8.342693, step = 4501 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.653\n",
            "INFO:tensorflow:loss = 6.9259086, step = 4601 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.646\n",
            "INFO:tensorflow:loss = 5.1302266, step = 4701 (0.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.147\n",
            "INFO:tensorflow:loss = 2.9191766, step = 4801 (0.328 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.325\n",
            "INFO:tensorflow:loss = 2.995292, step = 4901 (0.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.651\n",
            "INFO:tensorflow:loss = 1.2435905, step = 5001 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.558\n",
            "INFO:tensorflow:loss = 3.2201307, step = 5101 (0.306 sec)\n",
            "INFO:tensorflow:global_step/sec: 346.485\n",
            "INFO:tensorflow:loss = 4.9956894, step = 5201 (0.289 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.316\n",
            "INFO:tensorflow:loss = 16.677324, step = 5301 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 305.804\n",
            "INFO:tensorflow:loss = 2.2201834, step = 5401 (0.327 sec)\n",
            "INFO:tensorflow:global_step/sec: 318.802\n",
            "INFO:tensorflow:loss = 1.2917391, step = 5501 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 365.632\n",
            "INFO:tensorflow:loss = 7.2963495, step = 5601 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.201\n",
            "INFO:tensorflow:loss = 2.9897532, step = 5701 (0.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.451\n",
            "INFO:tensorflow:loss = 3.0797348, step = 5801 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.184\n",
            "INFO:tensorflow:loss = 5.6285405, step = 5901 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 308.934\n",
            "INFO:tensorflow:loss = 3.8034322, step = 6001 (0.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 314.754\n",
            "INFO:tensorflow:loss = 1.9028265, step = 6101 (0.321 sec)\n",
            "INFO:tensorflow:global_step/sec: 319.349\n",
            "INFO:tensorflow:loss = 9.415908, step = 6201 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.049\n",
            "INFO:tensorflow:loss = 3.0549617, step = 6301 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 322.17\n",
            "INFO:tensorflow:loss = 3.5137935, step = 6401 (0.315 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.913\n",
            "INFO:tensorflow:loss = 3.7595446, step = 6501 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 303.322\n",
            "INFO:tensorflow:loss = 7.5322237, step = 6601 (0.329 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.353\n",
            "INFO:tensorflow:loss = 3.3550963, step = 6701 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 319.801\n",
            "INFO:tensorflow:loss = 2.119227, step = 6801 (0.313 sec)\n",
            "INFO:tensorflow:global_step/sec: 324.68\n",
            "INFO:tensorflow:loss = 6.6985073, step = 6901 (0.307 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.834\n",
            "INFO:tensorflow:loss = 0.8963513, step = 7001 (0.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 325.677\n",
            "INFO:tensorflow:loss = 2.455381, step = 7101 (0.308 sec)\n",
            "INFO:tensorflow:global_step/sec: 307.584\n",
            "INFO:tensorflow:loss = 0.8584635, step = 7201 (0.324 sec)\n",
            "INFO:tensorflow:global_step/sec: 321.772\n",
            "INFO:tensorflow:loss = 0.53653735, step = 7301 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 327.45\n",
            "INFO:tensorflow:loss = 2.3221717, step = 7401 (0.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 323.84\n",
            "INFO:tensorflow:loss = 3.1382017, step = 7501 (0.311 sec)\n",
            "INFO:tensorflow:global_step/sec: 321.536\n",
            "INFO:tensorflow:loss = 4.386775, step = 7601 (0.309 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.616\n",
            "INFO:tensorflow:loss = 2.7386646, step = 7701 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 320.264\n",
            "INFO:tensorflow:loss = 2.0988386, step = 7801 (0.312 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.306\n",
            "INFO:tensorflow:loss = 0.5796536, step = 7901 (0.305 sec)\n",
            "INFO:tensorflow:global_step/sec: 337.699\n",
            "INFO:tensorflow:loss = 1.198743, step = 8001 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 329.165\n",
            "INFO:tensorflow:loss = 1.0699804, step = 8101 (0.299 sec)\n",
            "INFO:tensorflow:global_step/sec: 332.901\n",
            "INFO:tensorflow:loss = 6.6191707, step = 8201 (0.303 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.581\n",
            "INFO:tensorflow:loss = 1.0226707, step = 8301 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 310.495\n",
            "INFO:tensorflow:loss = 0.17685217, step = 8401 (0.322 sec)\n",
            "INFO:tensorflow:global_step/sec: 328.786\n",
            "INFO:tensorflow:loss = 1.0553914, step = 8501 (0.304 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.841\n",
            "INFO:tensorflow:loss = 3.0668492, step = 8601 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 331.906\n",
            "INFO:tensorflow:loss = 2.0189965, step = 8701 (0.300 sec)\n",
            "INFO:tensorflow:global_step/sec: 332.196\n",
            "INFO:tensorflow:loss = 4.6278286, step = 8801 (0.301 sec)\n",
            "INFO:tensorflow:global_step/sec: 330.883\n",
            "INFO:tensorflow:loss = 1.9447033, step = 8901 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 314.625\n",
            "INFO:tensorflow:loss = 1.6614962, step = 9001 (0.318 sec)\n",
            "INFO:tensorflow:global_step/sec: 335.643\n",
            "INFO:tensorflow:loss = 11.331603, step = 9101 (0.298 sec)\n",
            "INFO:tensorflow:global_step/sec: 338.118\n",
            "INFO:tensorflow:loss = 2.6481485, step = 9201 (0.296 sec)\n",
            "INFO:tensorflow:global_step/sec: 326.019\n",
            "INFO:tensorflow:loss = 2.299165, step = 9301 (0.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 332.595\n",
            "INFO:tensorflow:loss = 2.609383, step = 9401 (0.297 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.491\n",
            "INFO:tensorflow:loss = 3.9435174, step = 9501 (0.283 sec)\n",
            "INFO:tensorflow:global_step/sec: 340.972\n",
            "INFO:tensorflow:loss = 1.9460143, step = 9601 (0.291 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.995\n",
            "INFO:tensorflow:loss = 1.0749171, step = 9701 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.974\n",
            "INFO:tensorflow:loss = 1.5917519, step = 9801 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 358.519\n",
            "INFO:tensorflow:loss = 0.32568723, step = 9901 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.763\n",
            "INFO:tensorflow:loss = 2.4585884, step = 10001 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.224\n",
            "INFO:tensorflow:loss = 0.98096454, step = 10101 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 340.152\n",
            "INFO:tensorflow:loss = 0.42814752, step = 10201 (0.295 sec)\n",
            "INFO:tensorflow:global_step/sec: 352.821\n",
            "INFO:tensorflow:loss = 1.3214358, step = 10301 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 363.487\n",
            "INFO:tensorflow:loss = 1.5451972, step = 10401 (0.274 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.012\n",
            "INFO:tensorflow:loss = 4.1889343, step = 10501 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 383.165\n",
            "INFO:tensorflow:loss = 0.63194466, step = 10601 (0.258 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.18\n",
            "INFO:tensorflow:loss = 0.15116324, step = 10701 (0.261 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.224\n",
            "INFO:tensorflow:loss = 1.4659344, step = 10801 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 378.544\n",
            "INFO:tensorflow:loss = 0.86487937, step = 10901 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 384.885\n",
            "INFO:tensorflow:loss = 1.4999244, step = 11001 (0.260 sec)\n",
            "INFO:tensorflow:global_step/sec: 373.428\n",
            "INFO:tensorflow:loss = 2.726698, step = 11101 (0.268 sec)\n",
            "INFO:tensorflow:global_step/sec: 377.745\n",
            "INFO:tensorflow:loss = 0.8924685, step = 11201 (0.267 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.662\n",
            "INFO:tensorflow:loss = 0.45862168, step = 11301 (0.254 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.713\n",
            "INFO:tensorflow:loss = 0.6117783, step = 11401 (0.276 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.625\n",
            "INFO:tensorflow:loss = 0.8199939, step = 11501 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 381.58\n",
            "INFO:tensorflow:loss = 0.8497539, step = 11601 (0.263 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.198\n",
            "INFO:tensorflow:loss = 0.8030361, step = 11701 (0.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 359.442\n",
            "INFO:tensorflow:loss = 2.5641136, step = 11801 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 381.171\n",
            "INFO:tensorflow:loss = 1.9772762, step = 11901 (0.262 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.343\n",
            "INFO:tensorflow:loss = 0.91804177, step = 12001 (0.280 sec)\n",
            "INFO:tensorflow:global_step/sec: 368.52\n",
            "INFO:tensorflow:loss = 2.6236975, step = 12101 (0.271 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.276\n",
            "INFO:tensorflow:loss = 0.5276202, step = 12201 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.546\n",
            "INFO:tensorflow:loss = 0.96191937, step = 12301 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 372.251\n",
            "INFO:tensorflow:loss = 0.42146826, step = 12401 (0.268 sec)\n",
            "INFO:tensorflow:global_step/sec: 389.838\n",
            "INFO:tensorflow:loss = 2.0381367, step = 12501 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 351.815\n",
            "INFO:tensorflow:loss = 0.65897554, step = 12601 (0.284 sec)\n",
            "INFO:tensorflow:global_step/sec: 379.255\n",
            "INFO:tensorflow:loss = 0.7728862, step = 12701 (0.264 sec)\n",
            "INFO:tensorflow:global_step/sec: 390.385\n",
            "INFO:tensorflow:loss = 0.7492902, step = 12801 (0.256 sec)\n",
            "INFO:tensorflow:global_step/sec: 393.216\n",
            "INFO:tensorflow:loss = 0.3769825, step = 12901 (0.257 sec)\n",
            "INFO:tensorflow:global_step/sec: 382.111\n",
            "INFO:tensorflow:loss = 0.5149025, step = 13001 (0.259 sec)\n",
            "INFO:tensorflow:global_step/sec: 376.519\n",
            "INFO:tensorflow:loss = 1.8750558, step = 13101 (0.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.725\n",
            "INFO:tensorflow:loss = 3.8576498, step = 13201 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.856\n",
            "INFO:tensorflow:loss = 2.1110342, step = 13301 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 353.294\n",
            "INFO:tensorflow:loss = 1.8504378, step = 13401 (0.286 sec)\n",
            "INFO:tensorflow:global_step/sec: 356.99\n",
            "INFO:tensorflow:loss = 2.026789, step = 13501 (0.277 sec)\n",
            "INFO:tensorflow:global_step/sec: 357.82\n",
            "INFO:tensorflow:loss = 0.51276594, step = 13601 (0.282 sec)\n",
            "INFO:tensorflow:global_step/sec: 354.173\n",
            "INFO:tensorflow:loss = 0.5791937, step = 13701 (0.281 sec)\n",
            "INFO:tensorflow:global_step/sec: 333.108\n",
            "INFO:tensorflow:loss = 0.7497567, step = 13801 (0.302 sec)\n",
            "INFO:tensorflow:global_step/sec: 348.518\n",
            "INFO:tensorflow:loss = 0.05073889, step = 13901 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 355.318\n",
            "INFO:tensorflow:loss = 0.15404217, step = 14001 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 375.947\n",
            "INFO:tensorflow:loss = 1.467711, step = 14101 (0.265 sec)\n",
            "INFO:tensorflow:global_step/sec: 376.275\n",
            "INFO:tensorflow:loss = 0.793636, step = 14201 (0.266 sec)\n",
            "INFO:tensorflow:global_step/sec: 373.435\n",
            "INFO:tensorflow:loss = 0.69721454, step = 14301 (0.269 sec)\n",
            "INFO:tensorflow:global_step/sec: 345.846\n",
            "INFO:tensorflow:loss = 0.46668407, step = 14401 (0.288 sec)\n",
            "INFO:tensorflow:global_step/sec: 350.732\n",
            "INFO:tensorflow:loss = 1.9410957, step = 14501 (0.285 sec)\n",
            "INFO:tensorflow:global_step/sec: 360.125\n",
            "INFO:tensorflow:loss = 0.31805396, step = 14601 (0.279 sec)\n",
            "INFO:tensorflow:global_step/sec: 370.221\n",
            "INFO:tensorflow:loss = 0.16758274, step = 14701 (0.270 sec)\n",
            "INFO:tensorflow:global_step/sec: 362.688\n",
            "INFO:tensorflow:loss = 1.2840567, step = 14801 (0.278 sec)\n",
            "INFO:tensorflow:global_step/sec: 374.152\n",
            "INFO:tensorflow:loss = 0.600104, step = 14901 (0.263 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 15000 into /tmp/tfmodels/mnist_estimators/fashion_dnn_1534533961/model.ckpt.\n",
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-images-idx3-ubyte.gz to /tmp/tmpLQ6Xii.gz\n",
            "Downloading https://storage.googleapis.com/cvdf-datasets/mnist/t10k-labels-idx1-ubyte.gz to /tmp/tmpOJsXES.gz\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-08-17-19:31:45\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tfmodels/mnist_estimators/fashion_dnn_1534533961/model.ckpt-15000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-08-17-19:31:47\n",
            "INFO:tensorflow:Saving dict for global step 15000: accuracy = 0.9717, average_loss = 0.12119035, global_step = 15000, loss = 12.119035, recall = 0.997561\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15000: /tmp/tfmodels/mnist_estimators/fashion_dnn_1534533961/model.ckpt-15000\n",
            "INFO:tensorflow:Loss for final step: 0.49648166.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'accuracy': 0.9717,\n",
              "  'average_loss': 0.12119035,\n",
              "  'global_step': 15000,\n",
              "  'loss': 12.119035,\n",
              "  'recall': 0.997561},\n",
              " [])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "XDIu9Nh8TCUw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "You can see that the accuracy is significantly worse than with 'regular' MNIST. This dataset is harder! \n"
      ]
    },
    {
      "metadata": {
        "id": "xUP1Ni45TCUw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We can again make some predictions using our trained model:"
      ]
    },
    {
      "metadata": {
        "id": "LaLjj2PMTCUy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "8f5be969-f2ec-44f1-df77-2b1fabe11a40"
      },
      "cell_type": "code",
      "source": [
        "# predictions\n",
        "\n",
        "def predict_input_fn():\n",
        "  features = dataset.test(FASHION_DATA_DIR).skip(5575).take(5).batch(batch_size=1).make_one_shot_iterator().get_next()\n",
        "  return {'pixels': features[0]}, features[1]\n",
        "\n",
        "predictions = fashion_dnn_classifier.predict(input_fn=predict_input_fn)\n",
        "\n",
        "for prediction in predictions:\n",
        "    print(\"Predictions:    {} with probabilities {}\\n\".format(\n",
        "        prediction[\"classes\"], prediction[\"probabilities\"]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tfmodels/mnist_estimators/fashion_dnn_1534533961/model.ckpt-15000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Predictions:    ['9'] with probabilities [1.1235951e-11 4.6678330e-12 2.2534880e-11 2.0967983e-08 2.1024067e-10\n",
            " 2.0915565e-13 6.1805591e-20 6.6776922e-09 2.4371696e-10 1.0000000e+00]\n",
            "\n",
            "Predictions:    ['7'] with probabilities [1.1016747e-13 5.0261326e-15 5.6939733e-08 1.9198199e-11 3.3126205e-21\n",
            " 6.0149989e-19 1.7769626e-30 1.0000000e+00 1.1208151e-14 3.2354339e-09]\n",
            "\n",
            "Predictions:    ['4'] with probabilities [8.1624996e-10 4.7270603e-07 9.5392846e-11 2.8148083e-12 9.9997663e-01\n",
            " 4.1929996e-18 9.0256801e-13 1.5892836e-07 2.1653687e-14 2.2750701e-05]\n",
            "\n",
            "Predictions:    ['8'] with probabilities [5.3714581e-07 2.8001807e-12 7.3348552e-08 5.1633413e-09 7.0056250e-10\n",
            " 2.4048068e-09 5.1790679e-11 4.1439278e-12 9.9954635e-01 4.5305630e-04]\n",
            "\n",
            "Predictions:    ['5'] with probabilities [2.6515754e-17 1.8050825e-16 2.9415005e-20 9.6630958e-12 1.7879085e-24\n",
            " 1.0000000e+00 6.9191833e-11 1.1514808e-22 2.9448356e-12 8.5457161e-14]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "P5fEmWMhTCU1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1342
        },
        "outputId": "47891c2b-3596-4538-b009-b5fc7b2063a0"
      },
      "cell_type": "code",
      "source": [
        "# Bonus: What are the labels for these predictions?\n",
        "# This will fail if matplotlib is not installed. You can just skip it if so.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "pred_next_item = dataset.test(FASHION_DATA_DIR).skip(5575).take(5).batch(batch_size=1).make_one_shot_iterator().get_next()\n",
        "sess =  tf.Session()\n",
        "while True:\n",
        "  try:\n",
        "    item = sess.run(pred_next_item)\n",
        "    pred_label = item[1]\n",
        "    pred_image = item[0]\n",
        "    print(\"label: %s\" % pred_label)\n",
        "    sample = np.reshape(pred_image, (28,28))\n",
        "    plt.figure()\n",
        "    plt.imshow(sample, 'gray')\n",
        "  except tf.errors.OutOfRangeError:\n",
        "    break  "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label: [9]\n",
            "label: [7]\n",
            "label: [4]\n",
            "label: [8]\n",
            "label: [5]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wO47qmrcfWr5wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a175e1650>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a1759e710>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a1756db50>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKOgiEVDQRSKgoItEQEEXiYCCLhKB/weKGJlFnNg/+wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a17539fd0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD4CAYAAADFJPs2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f1a175011d0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "zCMLy0OSTCU4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<hr>\n",
        "Let's compare results again using TensorBoard.\n",
        "\n",
        "**Note**: If you're running this notebook on **colab**, you will not be able to run TensorBoard from the notebook, so you will need to skip this step.\n",
        "\n",
        "If TensorBoard is still running in a terminal window from before, it should pick up the new data automatically, since we pointed it to the parent directory of all the training runs we're doing. (If it doesn't seem to have done so, just reload).\n",
        "\n",
        "Otherwise, start up TensorBoard as follows in a new terminal window. (If you get a 'not found' error, make sure you've activated your virtual environment in that new window):\n",
        "\n",
        "```sh\n",
        "$ tensorboard --logdir=/tmp/tfmodels/mnist_estimators\n",
        "```\n",
        "Look for it at localhost:6006\n",
        "\n",
        "Or run the following (select Kernel --> Interrupt from the menu when you're done):"
      ]
    },
    {
      "metadata": {
        "id": "sJy6FKwnTCU6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=/tmp/tfmodels/mnist_estimators"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5e_xNydBTCU9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Exercise\n",
        "\n",
        "Try training a DNNClassifier model, using Fashion MNIST, with a .5 learning rate. \n",
        "Does this training do better or worse than the .1 learning rate on the Fashion MNIST dataset?"
      ]
    },
    {
      "metadata": {
        "id": "Mie-gpm_TCU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "23e0c668-2402-4fbe-ddf3-825dc48a2b91"
      },
      "cell_type": "code",
      "source": [
        "LR5 = .5\n",
        "# Your edits here\n",
        "fashion_dnn_classifier5 = ...\n",
        "\n",
        "...\n",
        "\n",
        "tf.estimator.train_and_evaluate(fashion_dnn_classifier5,\n",
        "                                train_spec,\n",
        "                                eval_spec)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-af17b0288fcc>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    fashion_dnn_classifier5 = ...\u001b[0m\n\u001b[0m                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "rmLAHXUiTCVC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Did this training run do better or worse than the .1 learning rate on fashion mnist?"
      ]
    },
    {
      "metadata": {
        "id": "YzwQJBiPTCVC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Copyright 2018 Google Inc. All Rights Reserved.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    http://www.apache.org/licenses/LICENSE-2.0\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License.\n"
      ]
    }
  ]
}